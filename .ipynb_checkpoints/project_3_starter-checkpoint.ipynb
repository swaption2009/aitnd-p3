{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Smart Beta Portfolio and Portfolio Optimization\n",
    "## Instructions\n",
    "Each problem consists of a function to implement and instructions on how to implement the function.  The parts of the function that need to be implemented are marked with a `# TODO` comment. After implementing the function, run the cell to test it against the unit tests we've provided. For each problem, we provide one or more unit tests from our `project_tests` package. These unit tests won't tell you if your answer is correct, but will warn you of any major errors. Your code will be checked for the correct solution when you submit it Udacity.\n",
    "\n",
    "## Packages\n",
    "When you implement the functions, you'll only need to use the [Pandas](https://pandas.pydata.org/) and [Numpy](http://www.numpy.org/) packages. Don't import any other packages, otherwise the grader willn't be able to run your code.\n",
    "\n",
    "The other packages that we're importing is `helper`, `project_helper`, and `project_tests`. These are custom packages built to help you solve the problems.  The `helper` and `project_helper` module contains utility functions and graph functions. The `project_tests` contains the unit tests for all the problems.\n",
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colour==0.1.5 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1))\n",
      "Collecting cvxopt==1.1.9 (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/91/2f/eed1cedf02cc83c7fcab357dbda76237f8f3ba881186cfa33dcdfdc153e8/cvxopt-1.1.9-cp36-cp36m-manylinux1_x86_64.whl (16.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 16.1MB 40kB/s  eta 0:00:01   32% |██████████▌                     | 5.3MB 33.8MB/s eta 0:00:01    61% |███████████████████▌            | 9.9MB 26.6MB/s eta 0:00:01    88% |████████████████████████████▎   | 14.2MB 29.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cycler==0.10.0 in /opt/conda/lib/python3.6/site-packages/cycler-0.10.0-py3.6.egg (from -r requirements.txt (line 3))\n",
      "Collecting matplotlib==2.1.1 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/34/50/d1649dafaecc91e360b1ca8defebb25f865e29928a98bc7d42ba3b1350e5/matplotlib-2.1.1-cp36-cp36m-manylinux1_x86_64.whl (15.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 15.0MB 44kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting numpy==1.13.3 (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/57/a7/e3e6bd9d595125e1abbe162e323fd2d06f6f6683185294b79cd2cdb190d5/numpy-1.13.3-cp36-cp36m-manylinux1_x86_64.whl (17.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 17.0MB 39kB/s  eta 0:00:01   55% |█████████████████▊              | 9.4MB 32.6MB/s eta 0:00:01    73% |███████████████████████▌        | 12.5MB 34.3MB/s eta 0:00:01    99% |████████████████████████████████| 17.0MB 31.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas==0.21.1 (from -r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/3a/e1/6c514df670b887c77838ab856f57783c07e8760f2e3d5939203a39735e0e/pandas-0.21.1-cp36-cp36m-manylinux1_x86_64.whl (26.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 26.2MB 24kB/s  eta 0:00:01    41% |█████████████▎                  | 10.9MB 28.8MB/s eta 0:00:01    51% |████████████████▌               | 13.5MB 24.4MB/s eta 0:00:01    56% |██████████████████▏             | 14.9MB 28.8MB/s eta 0:00:01    65% |█████████████████████           | 17.3MB 26.7MB/s eta 0:00:01    71% |██████████████████████▉         | 18.7MB 27.6MB/s eta 0:00:01    75% |████████████████████████▎       | 19.9MB 28.2MB/s eta 0:00:01    81% |██████████████████████████      | 21.3MB 31.2MB/s eta 0:00:01    91% |█████████████████████████████▎  | 24.0MB 30.3MB/s eta 0:00:01    94% |██████████████████████████████▍ | 24.9MB 20.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plotly==2.2.3 (from -r requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/99/a6/8214b6564bf4ace9bec8a26e7f89832792be582c042c47c912d3201328a0/plotly-2.2.3.tar.gz (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 585kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing==2.2.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 8))\n",
      "Requirement already satisfied: python-dateutil==2.6.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 9))\n",
      "Requirement already satisfied: pytz==2017.3 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 10))\n",
      "Requirement already satisfied: requests==2.18.4 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 11))\n",
      "Collecting scipy==1.0.0 (from -r requirements.txt (line 12))\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/5e/caa01ba7be11600b6a9d39265440d7b3be3d69206da887c42bef049521f2/scipy-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (50.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 50.0MB 12kB/s  eta 0:00:01  2% |█                               | 1.4MB 23.9MB/s eta 0:00:03    15% |█████                           | 7.8MB 26.4MB/s eta 0:00:02    18% |█████▉                          | 9.1MB 31.5MB/s eta 0:00:02    23% |███████▌                        | 11.7MB 30.3MB/s eta 0:00:02    26% |████████▎                       | 13.0MB 26.1MB/s eta 0:00:02    30% |█████████▉                      | 15.4MB 30.7MB/s eta 0:00:02    36% |███████████▌                    | 18.0MB 29.8MB/s eta 0:00:02    38% |████████████▌                   | 19.5MB 31.1MB/s eta 0:00:01    44% |██████████████▏                 | 22.1MB 29.2MB/s eta 0:00:01    47% |███████████████                 | 23.6MB 33.0MB/s eta 0:00:01    48% |███████████████▋                | 24.3MB 3.7MB/s eta 0:00:07    51% |████████████████▍               | 25.6MB 29.8MB/s eta 0:00:01    54% |█████████████████▎              | 27.1MB 33.7MB/s eta 0:00:01    56% |██████████████████▏             | 28.3MB 22.2MB/s eta 0:00:01    59% |███████████████████             | 29.7MB 33.2MB/s eta 0:00:01    64% |████████████████████▊           | 32.4MB 28.1MB/s eta 0:00:01    73% |███████████████████████▌        | 36.7MB 30.3MB/s eta 0:00:01    75% |████████████████████████▎       | 37.9MB 24.9MB/s eta 0:00:01    80% |█████████████████████████▉      | 40.4MB 25.4MB/s eta 0:00:01    83% |██████████████████████████▊     | 41.8MB 36.1MB/s eta 0:00:01    86% |███████████████████████████▊    | 43.3MB 31.6MB/s eta 0:00:01    89% |████████████████████████████▌   | 44.6MB 26.9MB/s eta 0:00:01    92% |█████████████████████████████▌  | 46.2MB 32.7MB/s eta 0:00:01    95% |██████████████████████████████▋ | 47.8MB 27.5MB/s eta 0:00:01    98% |███████████████████████████████▍| 49.1MB 20.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn==0.19.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 13))\n",
      "Requirement already satisfied: six==1.11.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 14))\n",
      "Collecting tqdm==4.19.5 (from -r requirements.txt (line 15))\n",
      "  Downloading https://files.pythonhosted.org/packages/71/3c/341b4fa23cb3abc335207dba057c790f3bb329f6757e1fcd5d347bcf8308/tqdm-4.19.5-py2.py3-none-any.whl (51kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 3.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.0.6 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 7))\n",
      "Requirement already satisfied: nbformat>=4.2 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 7))\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 11))\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 11))\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 11))\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 11))\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 7))\n",
      "Requirement already satisfied: traitlets>=4.1 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 7))\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 7))\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 7))\n",
      "Building wheels for collected packages: plotly\n",
      "  Running setup.py bdist_wheel for plotly ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/98/54/81/dd92d5b0858fac680cd7bdb8800eb26c001dd9f5dc8b1bc0ba\n",
      "Successfully built plotly\n",
      "Installing collected packages: cvxopt, numpy, matplotlib, pandas, plotly, scipy, tqdm\n",
      "  Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "      Successfully uninstalled numpy-1.12.1\n",
      "  Found existing installation: matplotlib 2.1.0\n",
      "    Uninstalling matplotlib-2.1.0:\n",
      "      Successfully uninstalled matplotlib-2.1.0\n",
      "  Found existing installation: pandas 0.20.3\n",
      "    Uninstalling pandas-0.20.3:\n",
      "      Successfully uninstalled pandas-0.20.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found existing installation: plotly 2.0.15\n",
      "    Uninstalling plotly-2.0.15:\n",
      "      Successfully uninstalled plotly-2.0.15\n",
      "  Found existing installation: scipy 0.19.1\n",
      "    Uninstalling scipy-0.19.1:\n",
      "      Successfully uninstalled scipy-0.19.1\n",
      "  Found existing installation: tqdm 4.11.2\n",
      "    Uninstalling tqdm-4.11.2:\n",
      "      Successfully uninstalled tqdm-4.11.2\n",
      "Successfully installed cvxopt-1.1.9 matplotlib-2.1.1 numpy-1.13.3 pandas-0.21.1 plotly-2.2.3 scipy-1.0.0 tqdm-4.19.5\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import helper\n",
    "import project_helper\n",
    "import project_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Data\n",
    "The data source we'll be using is the [Wiki End of Day data](https://www.quandl.com/databases/WIKIP) hosted at [Quandl](https://www.quandl.com). This contains data for many stocks, but we'll just be looking at the S&P 500 stocks. We'll also make things a little easier to solve by narrowing our range of time from 2007-06-30 to 2017-09-30.\n",
    "### Set API Key\n",
    "Set the `quandl_api_key` variable to your Quandl api key. You can find your Quandl api key [here](https://www.quandl.com/account/api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Add your Quandl API Key\n",
    "quandl_api_key  = 'zMsYyPT6939_oM8iZdg6'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Data: 442MB [00:06, 64.5MB/s]                          \n",
      "Transforming Data: 100%|██████████| 5/5 [01:17<00:00, 12.86s/Action]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "snp500_file_path = 'data/tickers_SnP500.txt'\n",
    "wiki_file_path = 'data/WIKI_PRICES.csv'\n",
    "start_date, end_date = '2013-07-01', '2017-06-30'\n",
    "use_columns = ['date', 'ticker', 'adj_close', 'adj_volume', 'ex-dividend']\n",
    "\n",
    "if not os.path.exists(wiki_file_path):\n",
    "    with open(snp500_file_path) as f:\n",
    "        tickers = f.read().split()\n",
    "    \n",
    "    helper.download_quandl_dataset(quandl_api_key, 'WIKI', 'PRICES', wiki_file_path, use_columns, tickers, start_date, end_date)\n",
    "else:\n",
    "    print('Data already downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(wiki_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Universe\n",
    "We'll be selecting dollar volume stocks for our stock universe. This universe is similar to large market cap stocks, because they are the highly liquid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percent_top_dollar = 0.2\n",
    "high_volume_symbols = project_helper.large_dollar_volume_stocks(df, 'adj_close', 'adj_volume', percent_top_dollar)\n",
    "df = df[df['ticker'].isin(high_volume_symbols)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-D Matrices\n",
    "In the previous projects, we used a [multiindex](https://pandas.pydata.org/pandas-docs/stable/advanced.html) to store all the data in a single dataframe. As you work with larger datasets, it come infeasable to store all the data in memory. Starting with this project, we'll be storing all our data as 2-D matrices to match what you'll be expecting in the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close = df.reset_index().pivot(index='ticker', columns='date', values='adj_close')\n",
    "volume = df.reset_index().pivot(index='ticker', columns='date', values='adj_volume')\n",
    "ex_dividend = df.reset_index().pivot(index='ticker', columns='date', values='ex-dividend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "To see what one of these 2-d matrices looks like, let's take a look at the closing prices matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "cells": {
          "fill": {
           "color": [
            "silver",
            "white"
           ]
          },
          "font": {
           "size": 13
          },
          "line": {
           "color": "silver"
          },
          "values": [
           [
            "AAL",
            "AAPL",
            "ABBV",
            "AGN",
            "AIG",
            "AMAT",
            "AMGN",
            "AMZN",
            "APC",
            "AVGO",
            "..."
           ],
           [
            "43.652",
            "53.722",
            "35.541",
            "124.075",
            "42.266",
            "13.735",
            "88.699",
            "282.100",
            "83.641",
            "35.212",
            "..."
           ],
           [
            "42.691",
            "54.939",
            "36.053",
            "122.482",
            "42.078",
            "13.740",
            "87.398",
            "283.730",
            "83.622",
            "36.026",
            "..."
           ],
           [
            "43.522",
            "55.243",
            "36.070",
            "122.640",
            "41.450",
            "13.907",
            "87.171",
            "284.030",
            "83.776",
            "36.129",
            "..."
           ],
           [
            "...",
            "...",
            "...",
            "...",
            "...",
            "...",
            "...",
            "...",
            "...",
            "...",
            "..."
           ]
          ]
         },
         "columnwidth": [
          1,
          3
         ],
         "header": {
          "fill": {
           "color": "silver"
          },
          "font": {
           "size": 13
          },
          "line": {
           "color": "silver"
          },
          "values": [
           "",
           "2013-07-01",
           "2013-07-02",
           "2013-07-03",
           "..."
          ]
         },
         "type": "table"
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"a934dcfd-8de9-4796-9838-a72727b665b9\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"a934dcfd-8de9-4796-9838-a72727b665b9\", [{\"type\": \"table\", \"columnwidth\": [1, 3], \"header\": {\"values\": [\"\", \"2013-07-01\", \"2013-07-02\", \"2013-07-03\", \"...\"], \"line\": {\"color\": \"silver\"}, \"fill\": {\"color\": \"silver\"}, \"font\": {\"size\": 13}}, \"cells\": {\"values\": [[\"AAL\", \"AAPL\", \"ABBV\", \"AGN\", \"AIG\", \"AMAT\", \"AMGN\", \"AMZN\", \"APC\", \"AVGO\", \"...\"], [\"43.652\", \"53.722\", \"35.541\", \"124.075\", \"42.266\", \"13.735\", \"88.699\", \"282.100\", \"83.641\", \"35.212\", \"...\"], [\"42.691\", \"54.939\", \"36.053\", \"122.482\", \"42.078\", \"13.740\", \"87.398\", \"283.730\", \"83.622\", \"36.026\", \"...\"], [\"43.522\", \"55.243\", \"36.070\", \"122.640\", \"41.450\", \"13.907\", \"87.171\", \"284.030\", \"83.776\", \"36.129\", \"...\"], [\"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\"]], \"line\": {\"color\": \"silver\"}, \"fill\": {\"color\": [\"silver\", \"white\"]}, \"font\": {\"size\": 13}}}], {}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"displayModeBar\": false})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"a934dcfd-8de9-4796-9838-a72727b665b9\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"a934dcfd-8de9-4796-9838-a72727b665b9\", [{\"type\": \"table\", \"columnwidth\": [1, 3], \"header\": {\"values\": [\"\", \"2013-07-01\", \"2013-07-02\", \"2013-07-03\", \"...\"], \"line\": {\"color\": \"silver\"}, \"fill\": {\"color\": \"silver\"}, \"font\": {\"size\": 13}}, \"cells\": {\"values\": [[\"AAL\", \"AAPL\", \"ABBV\", \"AGN\", \"AIG\", \"AMAT\", \"AMGN\", \"AMZN\", \"APC\", \"AVGO\", \"...\"], [\"43.652\", \"53.722\", \"35.541\", \"124.075\", \"42.266\", \"13.735\", \"88.699\", \"282.100\", \"83.641\", \"35.212\", \"...\"], [\"42.691\", \"54.939\", \"36.053\", \"122.482\", \"42.078\", \"13.740\", \"87.398\", \"283.730\", \"83.622\", \"36.026\", \"...\"], [\"43.522\", \"55.243\", \"36.070\", \"122.640\", \"41.450\", \"13.907\", \"87.171\", \"284.030\", \"83.776\", \"36.129\", \"...\"], [\"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\"]], \"line\": {\"color\": \"silver\"}, \"fill\": {\"color\": [\"silver\", \"white\"]}, \"font\": {\"size\": 13}}}], {}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"displayModeBar\": false})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project_helper.print_dataframe(close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Smart Beta Portfolio\n",
    "In Part 1 of this project, you'll build a smart beta portfolio using dividend yield. To see how well it performs, you'll compare this portfolio to an index.\n",
    "## Index Weights\n",
    "After building the smart beta portfolio, should compare it to a similar strategy or index.\n",
    "\n",
    "Implement `generate_dollar_volume_weights` to generate the weights for this index. For each date, generate the weights based on dollar volume traded for that date. For example, assume the following is dollar volume traded data:\n",
    "\n",
    "|          | 10/02/2010 | 10/03/2010 |\n",
    "|----------|------------|------------|\n",
    "| **AAPL** |      2     |      2     |\n",
    "| **BBC**  |      5     |      6     |\n",
    "| **GGL**  |      1     |      2     |\n",
    "| **ZGB**  |      6     |      5     |\n",
    "\n",
    "The weights should be the following:\n",
    "\n",
    "|          | 10/02/2010 | 10/03/2010 |\n",
    "|----------|------------|------------|\n",
    "| **AAPL** |    0.142   |    0.133   |\n",
    "| **BBC**  |    0.357   |    0.400   |\n",
    "| **GGL**  |    0.071   |    0.133   |\n",
    "| **ZGB**  |    0.428   |    0.333   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_dollar_volume_weights(close, volume):\n",
    "    \"\"\"\n",
    "    Generate dollar volume weights.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    close : DataFrame\n",
    "        Close price for each ticker and date\n",
    "    volume : str\n",
    "        Volume for each ticker and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dollar_volume_weights : DataFrame\n",
    "        The dollar volume weights for each ticker and date\n",
    "    \"\"\"\n",
    "    assert close.index.equals(volume.index)\n",
    "    assert close.columns.equals(volume.columns)\n",
    "    \n",
    "    #TODO: Implement function\n",
    "\n",
    "    return None\n",
    "\n",
    "project_tests.test_generate_dollar_volume_weights(generate_dollar_volume_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's generate the index weights using `generate_dollar_volume_weights` and view them using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_weights = generate_dollar_volume_weights(close, volume)\n",
    "project_helper.plot_weights(index_weights, 'Index Weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETF Weights\n",
    "Now that we have the index weights, it's time to build the weights for the smart beta ETF. Let's build an ETF portfolio that is based on dividends. This is a common factor used to build portfolios. Unlike most portfolios, we'll be using a single factor for simplicity.\n",
    "\n",
    "Implement `calculate_dividend_weights` to returns the weights for each stock based on its total dividend yield over time. This is similar to generating the weight for the index, but it's dividend data instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_dividend_weights(ex_dividend):\n",
    "    \"\"\"\n",
    "    Calculate dividend weights.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ex_dividend : DataFrame\n",
    "        Ex-dividend for each stock and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dividend_weights : DataFrame\n",
    "        Weights for each stock and date\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "\n",
    "    return None\n",
    "\n",
    "project_tests.test_calculate_dividend_weights(calculate_dividend_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's generate the ETF weights using `calculate_dividend_weights` and view them using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "etf_weights = calculate_dividend_weights(ex_dividend)\n",
    "project_helper.plot_weights(etf_weights, 'ETF Weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns\n",
    "Implement `generate_returns` to generate the returns. Note this isn't log returns. Since we're not dealing with volatility, we don't have to use log returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_returns(close):\n",
    "    \"\"\"\n",
    "    Generate returns for ticker and date.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    close : DataFrame\n",
    "        Close price for each ticker and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    returns : Dataframe\n",
    "        The returns for each ticker and date\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "\n",
    "    return None\n",
    "\n",
    "project_tests.test_generate_returns(generate_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's generate the closing returns using `generate_returns` and view them using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "returns = generate_returns(close)\n",
    "project_helper.plot_returns(returns, 'Close Returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Returns\n",
    "With the returns of each stock computed, we can use it to compute the returns for for an index or ETF. Implement `generate_weighted_returns` to create weighted returns using returns and weights for an Index or ETF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_weighted_returns(returns, weights):\n",
    "    \"\"\"\n",
    "    Generate weighted returns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "    weights : DataFrame\n",
    "        Weights for each ticker and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    weighted_returns : DataFrame\n",
    "        Weighted returns for each ticker and date\n",
    "    \"\"\"\n",
    "    assert returns.index.equals(weights.index)\n",
    "    assert returns.columns.equals(weights.columns)\n",
    "    \n",
    "    #TODO: Implement function\n",
    "\n",
    "    return None\n",
    "\n",
    "project_tests.test_generate_weighted_returns(generate_weighted_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's generate the etf and index returns using `generate_weighted_returns` and view them using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_weighted_returns = generate_weighted_returns(returns, index_weights)\n",
    "etf_weighted_returns = generate_weighted_returns(returns, etf_weights)\n",
    "project_helper.plot_returns(index_weighted_returns, 'Index Returns')\n",
    "project_helper.plot_returns(etf_weighted_returns, 'ETF Returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Returns\n",
    "Implement `calculate_cumulative_returns` to calculate the cumulative returns over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_cumulative_returns(returns):\n",
    "    \"\"\"\n",
    "    Calculate cumulative returns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cumulative_returns : Pandas Series\n",
    "        Cumulative returns for each date\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "project_tests.test_calculate_cumulative_returns(calculate_cumulative_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's generate the etf and index cumulative returns using `calculate_cumulative_returns` and compare the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_weighted_cumulative_returns = calculate_cumulative_returns(index_weighted_returns)\n",
    "etf_weighted_cumulative_returns = calculate_cumulative_returns(etf_weighted_returns)\n",
    "project_helper.plot_benchmark_returns(index_weighted_cumulative_returns, etf_weighted_cumulative_returns, 'Smart Beta ETF vs Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking Error\n",
    "In order to check the performance of the smart beta portfolio, we can compare it against the index. Let's generate the tracking error using the helper function's `tracking_error` and graph it over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smart_beta_tracking_error = project_helper.tracking_error(index_weighted_cumulative_returns, etf_weighted_cumulative_returns)\n",
    "project_helper.plot_tracking_error(smart_beta_tracking_error, 'Smart Beta Tracking Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Portfolio Optimization\n",
    "In Part 2, you'll optimize the index you created in part 1. You'll use `cvxopt` to optimize the convex problem of finding the optimal weights for the portfolio. Just like before, we'll compare these results to the index.\n",
    "## Covariance\n",
    "Implement `get_covariance` to calculate the covariance of `returns` and `weighted_index_returns`. We'll use this to feed into our convex optimization function. By using covariance, we can prevent the optimizer from going all in on a few stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_covariance(returns, weighted_index_returns):\n",
    "    \"\"\"\n",
    "    Calculate covariance matrices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "    weighted_index_returns : DataFrame\n",
    "        Weighted index returns for each ticker and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xtx, xty  : (2 dimensional Ndarray, 1 dimensional Ndarray)\n",
    "    \"\"\"\n",
    "    assert returns.index.equals(weighted_index_returns.index)\n",
    "    assert returns.columns.equals(weighted_index_returns.columns)\n",
    "    \n",
    "    #TODO: Implement function\n",
    "\n",
    "    return None, None\n",
    "\n",
    "project_tests.test_get_covariance(get_covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's look the the covariance generated from `get_covariance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtx, xty = get_covariance(returns, index_weighted_returns)\n",
    "xtx = pd.DataFrame(xtx, returns.index, returns.index)\n",
    "xty = pd.Series(xty, returns.index)\n",
    "project_helper.plot_covariance(xty, xtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Programming\n",
    "Now that you have the covariance, we can use this to optimize the weights. Run the following cell to generate optimal weights using helper function's `solve_qp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_optim_etf_weights = project_helper.solve_qp(xtx.values, xty.values)\n",
    "raw_optim_etf_weights_per_date = np.tile(raw_optim_etf_weights, (len(returns.columns), 1))\n",
    "optim_etf_weights = pd.DataFrame(raw_optim_etf_weights_per_date.T, returns.index, returns.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Portfolio\n",
    "With our optimized etf weights built using quadratic programming, let's compare it to the index. Run the next cell to calculate the optimized etf returns and compare the returns to the index returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optim_etf_returns = generate_weighted_returns(returns, optim_etf_weights)\n",
    "optim_etf_cumulative_returns = calculate_cumulative_returns(optim_etf_returns)\n",
    "project_helper.plot_benchmark_returns(index_weighted_cumulative_returns, optim_etf_cumulative_returns, 'Optimized ETF vs Index')\n",
    "\n",
    "optim_etf_tracking_error = project_helper.tracking_error(index_weighted_cumulative_returns, optim_etf_cumulative_returns)\n",
    "project_helper.plot_tracking_error(optim_etf_tracking_error, 'Optimized ETF Tracking Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebalance Portfolio\n",
    "The optimized etf portfolio used different weights for each day. After calculating in transaction fees, this amount of turnover to the portfolio can reduce the total returns. Let's find the optimal times to rebalance the portfolio instead of doing it every day.\n",
    "\n",
    "Implement `rebalance_portfolio` to rebalance a portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rebalance_portfolio(returns, weighted_index_returns, shift_size, chunk_size):\n",
    "    \"\"\"\n",
    "    Get weights for each rebalancing of the portfolio.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "    weighted_index_returns : DataFrame\n",
    "        Weighted index returns for each ticker and date\n",
    "    shift_size : int\n",
    "        The number of days between each rebalance\n",
    "    chunk_size : int\n",
    "        The number of days to look in the past for rebalancing\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_rebalance_weights  : list of Ndarrays\n",
    "        The etf weights for each point they are rebalanced\n",
    "    \"\"\"\n",
    "    assert returns.index.equals(weighted_index_returns.index)\n",
    "    assert returns.columns.equals(weighted_index_returns.columns)\n",
    "    assert shift_size > 0\n",
    "    assert chunk_size >= 0\n",
    "    \n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "project_tests.test_rebalance_portfolio(rebalance_portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to rebalance the portfolio using `rebalance_portfolio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunk_size = 250\n",
    "shift_size = 5\n",
    "all_rebalance_weights = rebalance_portfolio(returns, index_weighted_returns, shift_size, chunk_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Rebalance Cost\n",
    "With the portfolio rebalanced, we need to use a metric to measure the cost of rebalancing the portfolio. Implement `get_rebalance_cost` to calculate the rebalance cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rebalance_cost(all_rebalance_weights, shift_size, rebalance_count):\n",
    "    \"\"\"\n",
    "    Get the cost of all the rebalancing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_rebalance_weights : list of Ndarrays\n",
    "        ETF Returns for each ticker and date\n",
    "    shift_size : int\n",
    "        The number of days between each rebalance\n",
    "    rebalance_count : int\n",
    "        Number of times the portfolio was rebalanced\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rebalancing_cost  : float\n",
    "        The cost of all the rebalancing\n",
    "    \"\"\"\n",
    "    assert shift_size > 0\n",
    "    assert rebalance_count > 0\n",
    "    \n",
    "    #TODO: Implement function\n",
    "\n",
    "    return None\n",
    "\n",
    "project_tests.test_get_rebalance_cost(get_rebalance_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to get the rebalance cost from  `get_rebalance_cost`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unconstrained_costs = get_rebalance_cost(all_rebalance_weights, shift_size, returns.shape[1])\n",
    "print(unconstrained_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Now that you're done with the project, it's time to submit it. Click the submit button in the bottom right. One of our reviewers will give you feedback on your project with a pass or not passed grade. You can continue to the next section while you wait for feedback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aind-dl]",
   "language": "python",
   "name": "conda-env-aind-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
